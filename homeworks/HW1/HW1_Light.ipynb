{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "lonely-delta",
      "metadata": {
        "id": "lonely-delta",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Нейронные сети и глубокое обучение, МНАД ВШЭ\n",
        "\n",
        "## Домашнее задание 1. Полносвязные нейронные сети.\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Максимально допустимая оценка за работу без бонусов — 10 баллов. Сдавать задание после указанного срока жесткого дедлайна нельзя.\n",
        "\n",
        "Сдача работы после мягкого дедлайна штрафуется ступенчато, -1 балл в сутки. Два раза за семестр (2 модуля) студентам предоставляется возможность использовать отсрочку и сдать в жесткий дедлайн без штрафа.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "Использование генеративных моделей допустимо на следующих условиях:\n",
        "- Количество кода, написанное генеративными моделями, не превышает 30%\n",
        "- Указана модель, использованная для генерации, а также промпт\n",
        "- В конце работы необходимо описать свой опыт использования генеративного ИИ для решения данного домашнего задания. Укажите как часто Вам приходилось исправлять код своими руками или просить модель что-то исправить. Было ли это быстрее, чем написать код самим?\n",
        "\n",
        "В случае невыполнения этих требований работа не оценивается и оценка за неё не превышает 0 баллов.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит обучить полносвязную нейронную сеть для предсказания года выпуска песни по ее аудио-признакам. Для этого мы будем использовать [Million Songs Dataset](https://samyzaf.com/ML/song_year/song_year.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DieL9-DxNKq9"
      },
      "id": "DieL9-DxNKq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "lonely-component",
      "metadata": {
        "id": "lonely-component",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from IPython.display import clear_output\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "plt.rcParams.update({\"font.size\": 16})\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(0xFA1AFE1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "marine-logistics",
      "metadata": {
        "id": "marine-logistics"
      },
      "source": [
        "Начнем с того, что скачаем и загрузим данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bridal-archive",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bridal-archive",
        "outputId": "18a82b8d-09ca-49ef-93d7-a963daac20d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-22 20:16:22--  https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘data.txt.zip’\n",
            "\n",
            "data.txt.zip            [           <=>      ] 201.24M  46.9MB/s    in 4.7s    \n",
            "\n",
            "2025-11-22 20:16:27 (42.9 MB/s) - ‘data.txt.zip’ saved [211011981]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "welsh-heavy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "welsh-heavy",
        "outputId": "7db840b2-b29a-42e2-928c-38a5f43d25bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6   \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "              7         8         9   ...        81         82         83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "               84        85        86         87        88         89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "              90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-404f59a7-6c96-4129-bff3-c79d1bac4fc3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows × 91 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-404f59a7-6c96-4129-bff3-c79d1bac4fc3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-404f59a7-6c96-4129-bff3-c79d1bac4fc3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-404f59a7-6c96-4129-bff3-c79d1bac4fc3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8dcb00be-dab1-4b9a-b6b0-c999a923af6a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dcb00be-dab1-4b9a-b6b0-c999a923af6a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8dcb00be-dab1-4b9a-b6b0-c999a923af6a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv(\"data.txt.zip\", header=None)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "single-hearts",
      "metadata": {
        "id": "single-hearts"
      },
      "source": [
        "Посмотрим на статистики по данным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "interior-bacteria",
      "metadata": {
        "id": "interior-bacteria",
        "outputId": "b5d419a6-9a98-4cac-bfac-2c803b2549a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0              1              2              3   \\\n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000   \n",
              "mean     1998.397082      43.387126       1.289554       8.658347   \n",
              "std        10.931046       6.067558      51.580351      35.268585   \n",
              "min      1922.000000       1.749000    -337.092500    -301.005060   \n",
              "25%      1994.000000      39.954690     -26.059520     -11.462710   \n",
              "50%      2002.000000      44.258500       8.417850      10.476320   \n",
              "75%      2006.000000      47.833890      36.124010      29.764820   \n",
              "max      2011.000000      61.970140     384.065730     322.851430   \n",
              "\n",
              "                  4              5              6              7   \\\n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000   \n",
              "mean        1.164124      -6.553601      -9.521975      -2.391089   \n",
              "std        16.322790      22.860785      12.857751      14.571873   \n",
              "min      -154.183580    -181.953370     -81.794290    -188.214000   \n",
              "25%        -8.487500     -20.666450     -18.440990     -10.780600   \n",
              "50%        -0.652840      -6.007770     -11.188390      -2.046670   \n",
              "75%         8.787540       7.741870      -2.388960       6.508580   \n",
              "max       335.771820     262.068870     166.236890     172.402680   \n",
              "\n",
              "                  8              9   ...             81             82  \\\n",
              "count  515345.000000  515345.000000  ...  515345.000000  515345.000000   \n",
              "mean       -1.793236       3.727876  ...      15.755406     -73.461500   \n",
              "std         7.963827      10.582861  ...      32.099635     175.618889   \n",
              "min       -72.503850    -126.479040  ...    -437.722030   -4402.376440   \n",
              "25%        -6.468420      -2.293660  ...      -1.812650    -139.555160   \n",
              "50%        -1.736450       3.822310  ...       9.171850     -53.090060   \n",
              "75%         2.913450       9.961820  ...      26.274480      13.478730   \n",
              "max       126.741270     146.297950  ...     840.973380    4469.454870   \n",
              "\n",
              "                  83             84             85             86  \\\n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000   \n",
              "mean       41.542422      37.934119       0.315751      17.669213   \n",
              "std       122.228799      95.050631      16.161764     114.427905   \n",
              "min     -1810.689190   -3098.350310    -341.789120   -3168.924570   \n",
              "25%       -20.986900      -4.669540      -6.781590     -31.580610   \n",
              "50%        28.791060      33.623630       0.820840      15.598470   \n",
              "75%        89.661770      77.785800       8.470990      67.794960   \n",
              "max      3210.701700    1734.079690     260.544900    3662.065650   \n",
              "\n",
              "                  87             88             89             90  \n",
              "count  515345.000000  515345.000000  515345.000000  515345.000000  \n",
              "mean      -26.315336       4.458641      20.035136       1.329105  \n",
              "std       173.977336      13.346557     185.558247      22.088576  \n",
              "min     -4319.992320    -236.039260   -7458.378150    -381.424430  \n",
              "25%      -101.530300      -2.566090     -59.509270      -8.820210  \n",
              "50%       -21.204120       3.117640       7.759730       0.053050  \n",
              "75%        52.389330       9.967740      86.351610       9.679520  \n",
              "max      2833.608950     463.419500    7393.398440     677.899630  \n",
              "\n",
              "[8 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a69dd087-7d22-4a53-a1cd-543480920503\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "      <td>515345.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1998.397082</td>\n",
              "      <td>43.387126</td>\n",
              "      <td>1.289554</td>\n",
              "      <td>8.658347</td>\n",
              "      <td>1.164124</td>\n",
              "      <td>-6.553601</td>\n",
              "      <td>-9.521975</td>\n",
              "      <td>-2.391089</td>\n",
              "      <td>-1.793236</td>\n",
              "      <td>3.727876</td>\n",
              "      <td>...</td>\n",
              "      <td>15.755406</td>\n",
              "      <td>-73.461500</td>\n",
              "      <td>41.542422</td>\n",
              "      <td>37.934119</td>\n",
              "      <td>0.315751</td>\n",
              "      <td>17.669213</td>\n",
              "      <td>-26.315336</td>\n",
              "      <td>4.458641</td>\n",
              "      <td>20.035136</td>\n",
              "      <td>1.329105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>10.931046</td>\n",
              "      <td>6.067558</td>\n",
              "      <td>51.580351</td>\n",
              "      <td>35.268585</td>\n",
              "      <td>16.322790</td>\n",
              "      <td>22.860785</td>\n",
              "      <td>12.857751</td>\n",
              "      <td>14.571873</td>\n",
              "      <td>7.963827</td>\n",
              "      <td>10.582861</td>\n",
              "      <td>...</td>\n",
              "      <td>32.099635</td>\n",
              "      <td>175.618889</td>\n",
              "      <td>122.228799</td>\n",
              "      <td>95.050631</td>\n",
              "      <td>16.161764</td>\n",
              "      <td>114.427905</td>\n",
              "      <td>173.977336</td>\n",
              "      <td>13.346557</td>\n",
              "      <td>185.558247</td>\n",
              "      <td>22.088576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1922.000000</td>\n",
              "      <td>1.749000</td>\n",
              "      <td>-337.092500</td>\n",
              "      <td>-301.005060</td>\n",
              "      <td>-154.183580</td>\n",
              "      <td>-181.953370</td>\n",
              "      <td>-81.794290</td>\n",
              "      <td>-188.214000</td>\n",
              "      <td>-72.503850</td>\n",
              "      <td>-126.479040</td>\n",
              "      <td>...</td>\n",
              "      <td>-437.722030</td>\n",
              "      <td>-4402.376440</td>\n",
              "      <td>-1810.689190</td>\n",
              "      <td>-3098.350310</td>\n",
              "      <td>-341.789120</td>\n",
              "      <td>-3168.924570</td>\n",
              "      <td>-4319.992320</td>\n",
              "      <td>-236.039260</td>\n",
              "      <td>-7458.378150</td>\n",
              "      <td>-381.424430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1994.000000</td>\n",
              "      <td>39.954690</td>\n",
              "      <td>-26.059520</td>\n",
              "      <td>-11.462710</td>\n",
              "      <td>-8.487500</td>\n",
              "      <td>-20.666450</td>\n",
              "      <td>-18.440990</td>\n",
              "      <td>-10.780600</td>\n",
              "      <td>-6.468420</td>\n",
              "      <td>-2.293660</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.812650</td>\n",
              "      <td>-139.555160</td>\n",
              "      <td>-20.986900</td>\n",
              "      <td>-4.669540</td>\n",
              "      <td>-6.781590</td>\n",
              "      <td>-31.580610</td>\n",
              "      <td>-101.530300</td>\n",
              "      <td>-2.566090</td>\n",
              "      <td>-59.509270</td>\n",
              "      <td>-8.820210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2002.000000</td>\n",
              "      <td>44.258500</td>\n",
              "      <td>8.417850</td>\n",
              "      <td>10.476320</td>\n",
              "      <td>-0.652840</td>\n",
              "      <td>-6.007770</td>\n",
              "      <td>-11.188390</td>\n",
              "      <td>-2.046670</td>\n",
              "      <td>-1.736450</td>\n",
              "      <td>3.822310</td>\n",
              "      <td>...</td>\n",
              "      <td>9.171850</td>\n",
              "      <td>-53.090060</td>\n",
              "      <td>28.791060</td>\n",
              "      <td>33.623630</td>\n",
              "      <td>0.820840</td>\n",
              "      <td>15.598470</td>\n",
              "      <td>-21.204120</td>\n",
              "      <td>3.117640</td>\n",
              "      <td>7.759730</td>\n",
              "      <td>0.053050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2006.000000</td>\n",
              "      <td>47.833890</td>\n",
              "      <td>36.124010</td>\n",
              "      <td>29.764820</td>\n",
              "      <td>8.787540</td>\n",
              "      <td>7.741870</td>\n",
              "      <td>-2.388960</td>\n",
              "      <td>6.508580</td>\n",
              "      <td>2.913450</td>\n",
              "      <td>9.961820</td>\n",
              "      <td>...</td>\n",
              "      <td>26.274480</td>\n",
              "      <td>13.478730</td>\n",
              "      <td>89.661770</td>\n",
              "      <td>77.785800</td>\n",
              "      <td>8.470990</td>\n",
              "      <td>67.794960</td>\n",
              "      <td>52.389330</td>\n",
              "      <td>9.967740</td>\n",
              "      <td>86.351610</td>\n",
              "      <td>9.679520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2011.000000</td>\n",
              "      <td>61.970140</td>\n",
              "      <td>384.065730</td>\n",
              "      <td>322.851430</td>\n",
              "      <td>335.771820</td>\n",
              "      <td>262.068870</td>\n",
              "      <td>166.236890</td>\n",
              "      <td>172.402680</td>\n",
              "      <td>126.741270</td>\n",
              "      <td>146.297950</td>\n",
              "      <td>...</td>\n",
              "      <td>840.973380</td>\n",
              "      <td>4469.454870</td>\n",
              "      <td>3210.701700</td>\n",
              "      <td>1734.079690</td>\n",
              "      <td>260.544900</td>\n",
              "      <td>3662.065650</td>\n",
              "      <td>2833.608950</td>\n",
              "      <td>463.419500</td>\n",
              "      <td>7393.398440</td>\n",
              "      <td>677.899630</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 91 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a69dd087-7d22-4a53-a1cd-543480920503')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a69dd087-7d22-4a53-a1cd-543480920503 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a69dd087-7d22-4a53-a1cd-543480920503');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5f999893-3501-4d5d-a0f8-5d0c31f90ed3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f999893-3501-4d5d-a0f8-5d0c31f90ed3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5f999893-3501-4d5d-a0f8-5d0c31f90ed3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-writer",
      "metadata": {
        "id": "broad-writer"
      },
      "source": [
        "Целевая переменная, год выпуска песни, записана в первом столбце. Посмотрим на ее распределение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "exposed-small",
      "metadata": {
        "id": "exposed-small",
        "outputId": "56f95c6e-8cb3-4066-952e-c7fa84fd72f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Range: 1922 - 2011\n",
            "Unique values: 89\n"
          ]
        }
      ],
      "source": [
        "plt.hist(df.iloc[:, 0], bins=20)\n",
        "plt.xlabel(\"year\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.show()\n",
        "print(f\"Range: {df.iloc[:, 0].min()} - {df.iloc[:, 0].max()}\")\n",
        "print(f\"Unique values: {np.unique(df.iloc[:, 0]).size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noted-rebecca",
      "metadata": {
        "id": "noted-rebecca"
      },
      "source": [
        "Разобьем данные на обучение и тест (не меняйте здесь ничего, чтобы сплит был одинаковым у всех)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "presidential-wisconsin",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "presidential-wisconsin",
        "outputId": "618d2386-7edf-453e-826c-9ecc893b9e8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((386508, 90), (128837, 90))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "train_size = int(0.75 * X.shape[0])\n",
        "X_train = X[:train_size, :]\n",
        "y_train = y[:train_size]\n",
        "X_test = X[train_size:, :]\n",
        "y_test = y[train_size:]\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaptive-quantity",
      "metadata": {
        "id": "adaptive-quantity"
      },
      "source": [
        "**Задание 0 (0 баллов, но при невыполнении максимальная оценка за всю работу &mdash; 0 баллов).** Мы будем использовать MSE как метрику качества. Прежде чем обучать нейронные сети, нам нужно проверить несколько простых бейзлайнов, чтобы было с чем сравнить более сложные алгоритмы. Для этого обучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе (также пропишите текстом, какая константа будет лучшей для MSE)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge регрессия\n",
        "ridge_model = Ridge()\n",
        "ridge_model.fit(X_train, y_train)\n",
        "y_pred = ridge_model.predict(X_test)\n",
        "mse_ridge = mean_squared_error(y_test, y_pred)"
      ],
      "metadata": {
        "id": "cUYYcp33ORXu"
      },
      "id": "cUYYcp33ORXu",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# константный прогноз\n",
        "dummy_model = DummyRegressor(strategy='mean')\n",
        "dummy_model.fit(X_train, y_train)\n",
        "y_pred_constant = dummy_model.predict(X_test)\n",
        "mse_constant = mean_squared_error(y_test, y_pred_constant)"
      ],
      "metadata": {
        "id": "LDoDw6AmOd8g"
      },
      "id": "LDoDw6AmOd8g",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Ridge регрессия MSE: {mse_ridge}\")\n",
        "print(f\"Константный прогноз MSE: {mse_constant}\")\n",
        "print(f\"Наилучшая константа для MSE: {float(dummy_model.constant_[0][0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzZsQVL8RBt3",
        "outputId": "dd09e8a1-ee1b-4fe2-9dd9-858af38809b5"
      },
      "id": "VzZsQVL8RBt3",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge регрессия MSE: 89.74966397222076\n",
            "Константный прогноз MSE: 117.62580230734426\n",
            "Наилучшая константа для MSE: 1998.3753660985026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4c6b65",
      "metadata": {
        "id": "0f4c6b65"
      },
      "source": [
        "**Ответ:** MSE метрику получили примерно 90 для Ridge регрессии и 117 для константного прогноза. Будем по ним ориентироваться при получении качества на нейронке"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suspected-arbitration",
      "metadata": {
        "id": "suspected-arbitration"
      },
      "source": [
        "Теперь приступим к экспериментам с нейросетями. Для начала отделим от данных валидацию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "offensive-publication",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "offensive-publication",
        "outputId": "10781ca4-030d-4877-df15-576344447b84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((289881, 90), (96627, 90))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=0xE2E4\n",
        ")\n",
        "X_train.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "modern-platform",
      "metadata": {
        "id": "modern-platform"
      },
      "source": [
        "## Часть 1. Заводим нейронную сеть (5 баллов)\n",
        "\n",
        "**Задание 1.1 (0.5 баллов).** Заполните пропуски в функции `train_and_validate`. Она поможет нам запускать эксперименты. Можете также реализовать поддержку обучения на GPU, чтобы эксперименты считались быстрее. Бесплатно воспользоваться GPU можно на сервисах **Google Colab** и **Kaggle**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cooperative-bedroom",
      "metadata": {
        "id": "cooperative-bedroom"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_losses, train_metrics, val_losses, val_metrics):\n",
        "    \"\"\"\n",
        "    Plot losses and metrics while training\n",
        "      - train_losses: sequence of train losses\n",
        "      - train_metrics: sequence of train MSE values\n",
        "      - val_losses: sequence of validation losses\n",
        "      - val_metrics: sequence of validation MSE values\n",
        "    \"\"\"\n",
        "    clear_output()\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"train\")\n",
        "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"val\")\n",
        "    axs[1].plot(range(1, len(train_metrics) + 1), train_metrics, label=\"train\")\n",
        "    axs[1].plot(range(1, len(val_metrics) + 1), val_metrics, label=\"val\")\n",
        "\n",
        "    if max(train_losses) / min(train_losses) > 10:\n",
        "        axs[0].set_yscale(\"log\")\n",
        "\n",
        "    if max(train_metrics) / min(train_metrics) > 10:\n",
        "        axs[0].set_yscale(\"log\")\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.set_xlabel(\"epoch\")\n",
        "        ax.legend()\n",
        "\n",
        "    axs[0].set_ylabel(\"loss\")\n",
        "    axs[1].set_ylabel(\"MSE\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_and_validate(\n",
        "    model,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    metric,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    verbose=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train and validate neural network\n",
        "      - model: neural network to train\n",
        "      - optimizer: optimizer chained to a model\n",
        "      - criterion: loss function class\n",
        "      - metric: function to measure MSE taking neural networks predictions\n",
        "                 and ground truth labels\n",
        "      - train_loader: DataLoader with train set\n",
        "      - val_loader: DataLoader with validation set\n",
        "      - num_epochs: number of epochs to train\n",
        "      - verbose: whether to plot metrics during training\n",
        "    Returns:\n",
        "      - train_mse: training MSE over the last epoch\n",
        "      - val_mse: validation MSE after the last epoch\n",
        "    \"\"\"\n",
        "    train_losses, val_losses = [], []\n",
        "    train_metrics, val_metrics = [], []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss, running_metric = 0, 0\n",
        "        pbar = (\n",
        "            tqdm(train_loader, desc=f\"Training {epoch}/{num_epochs}\")\n",
        "            if verbose\n",
        "            else train_loader\n",
        "        )\n",
        "\n",
        "        for i, (X_batch, y_batch) in enumerate(pbar, 1):\n",
        "            \"\"\"\n",
        "            YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "            Do forward and backward passes\n",
        "            predictions = ...\n",
        "            loss = ...\n",
        "            \"\"\"\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric_value = metric(predictions, y_batch)\n",
        "                if type(metric_value) == torch.Tensor:\n",
        "                    metric_value = metric_value.item()\n",
        "                running_loss += loss.item() * X_batch.shape[0]\n",
        "                running_metric += metric_value * X_batch.shape[0]\n",
        "\n",
        "            if verbose and i % 100 == 0:\n",
        "                pbar.set_postfix({\"loss\": loss.item(), \"MSE\": metric_value})\n",
        "\n",
        "        train_losses += [running_loss / len(train_loader.dataset)]\n",
        "        train_metrics += [running_metric / len(train_loader.dataset)]\n",
        "\n",
        "        model.eval()\n",
        "        running_loss, running_metric = 0, 0\n",
        "        pbar = (\n",
        "            tqdm(val_loader, desc=f\"Validating {epoch}/{num_epochs}\")\n",
        "            if verbose\n",
        "            else val_loader\n",
        "        )\n",
        "\n",
        "        for i, (X_batch, y_batch) in enumerate(pbar, 1):\n",
        "            with torch.no_grad():\n",
        "                \"\"\"\n",
        "                YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "                Do evaluation\n",
        "                predictions = ...\n",
        "                loss = ...\n",
        "                \"\"\"\n",
        "\n",
        "                metric_value = metric(predictions, y_batch)\n",
        "                if type(metric_value) == torch.Tensor:\n",
        "                    metric_value = metric_value.item()\n",
        "                running_loss += loss.item() * X_batch.shape[0]\n",
        "                running_metric += metric_value * X_batch.shape[0]\n",
        "\n",
        "            if verbose and i % 100 == 0:\n",
        "                pbar.set_postfix({\"loss\": loss.item(), \"MSE\": metric_value})\n",
        "\n",
        "        val_losses += [running_loss / len(val_loader.dataset)]\n",
        "        val_metrics += [running_metric / len(val_loader.dataset)]\n",
        "\n",
        "        if verbose:\n",
        "            plot_losses(train_losses, train_metrics, val_losses, val_metrics)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Validation MSE: {val_metrics[-1]:.3f}\")\n",
        "\n",
        "    return train_metrics[-1], val_metrics[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adjacent-grace",
      "metadata": {
        "id": "adjacent-grace"
      },
      "source": [
        "**Задание 1.2 (0.75 балла).** Попробуем обучить нашу первую нейронную сеть. Здесь целевая переменная дискретная &mdash; это год выпуска песни. Поэтому будем учить сеть на классификацию c помощью [кросс-энтропийной функции потерь](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
        "\n",
        "- В качестве архитектуры сети возьмите два линейных слоя с активацией ReLU между ними c числом скрытых нейронов, равным 128.\n",
        "- Используйте SGD с `lr=1e-2`.\n",
        "- Возьмите размер мини-батча около 32-64, примерно 3-4 эпох обучения должно быть достаточно.\n",
        "- Скорее всего вам пригодится `torch.utils.data.TensorDataset`. Когда будете конвертировать numpy-массивы в torch-тензоры, используйте тип `torch.float32`.\n",
        "- Также преобразуйте целевую переменную так, чтобы ее значения принимали значения от $0$ до $C-1$, где $C$ &mdash; число классов (лучше передайте преобразованное значение в TensorDataset, исходное нам еще пригодится)\n",
        "- В качестве параметра `metric` в `train_and_validate` передайте lambda-выражение, которое считает MSE по выходу нейронной сети и целевой переменной. В случае классификации предсказывается класс с наибольшей вероятностью (или, что то же самое, с наибольшим значением **логита**$^1$).\n",
        "\n",
        "$^1$ **Логит** &mdash; выход последнего линейного слоя, может принимать любые вещественные значения. Если применить Softmax к логитам, то получатся вероятности распределения классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "manufactured-beverage",
      "metadata": {
        "id": "manufactured-beverage"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "postal-kingdom",
      "metadata": {
        "id": "postal-kingdom"
      },
      "source": [
        "**Задание 1.3 (0.5 балла).** Прокомментируйте ваши наблюдения. Удалось ли побить бейзлайн? Как вы думаете, хорошая ли идея учить классификатор для этой задачи? Почему?\n",
        "\n",
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gorgeous-italy",
      "metadata": {
        "id": "gorgeous-italy"
      },
      "source": [
        "**Задание 1.4 (0.75 балла).** Теперь попробуем решать задачу как регрессию. Обучите нейронную сеть на [MSE](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html).\n",
        "\n",
        "- Используйте такие же гиперпараметры обучения.\n",
        "- Когда передаете целевую переменную в TensorDataset, сделайте reshape в (-1, 1).\n",
        "- Не забудьте изменить lambda-выражение, которые вы передаете в `train_and_validate`.\n",
        "- Если что-то пойдет не так, можете попробовать меньшие значения `lr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contrary-justice",
      "metadata": {
        "id": "contrary-justice"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nonprofit-passenger",
      "metadata": {
        "id": "nonprofit-passenger"
      },
      "source": [
        "**Задание 1.5 (0.5 балла).** Получилось ли у вас стабилизировать обучение? Помогли ли меньшие значения `lr`? Стало ли лучше от замены классификации на регрессию? Как вы думаете, почему так происходит? В качестве подсказки можете посмотреть на распределение целевой переменной и магнитуду значений признаков.\n",
        "\n",
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tested-cleaners",
      "metadata": {
        "id": "tested-cleaners"
      },
      "source": [
        "**Задание 1.6 (0.75 балла).** Начнем с того, что попробуем отнормировать целевую переменную. Для этого воспользуемся min-max нормализацией, чтобы целевая переменная принимала значения от 0 до 1. Реализуйте функции `normalize` и `denormalize`, которые, соответственно, нормируют целевую переменную и применяют обратное преобразование. Минимум и максимум оцените по обучающей выборке (то есть эти константы должны быть фиксированными и не зависеть от передаваемой выборки)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "downtown-stake",
      "metadata": {
        "id": "downtown-stake"
      },
      "outputs": [],
      "source": [
        "def normalize(sample):\n",
        "    \"\"\"\n",
        "    Min-max normalization to convert sample to [0, 1] range\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "    pass\n",
        "\n",
        "\n",
        "def denormalize(sample):\n",
        "    \"\"\"\n",
        "    Denormalize sample from [0, 1] to initial range\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "official-booking",
      "metadata": {
        "id": "official-booking"
      },
      "source": [
        "Теперь повторите эксперимент из **задания 1.4**, обучаясь на нормированной целевой переменной. Сделаем также еще одно изменение: добавим [сигмоидную активацию](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) после последнего линейного слоя сети. Таким образом мы гарантируем, что нейронная сеть предсказывает числа из промежутка $[0, 1]$. Использование активации - довольно распространенный прием, когда мы хотим получить числа из определенного диапазона значений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "olive-brick",
      "metadata": {
        "id": "olive-brick"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "twenty-pulse",
      "metadata": {
        "id": "twenty-pulse"
      },
      "source": [
        "**Задание 1.7 (0.5 балла).** Сравните результаты этого эксперимента с предыдущим запуском.\n",
        "\n",
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "colonial-slovakia",
      "metadata": {
        "id": "colonial-slovakia"
      },
      "source": [
        "**Задание 1.8 (0.75 балла).** На этот раз попробуем отнормировать не только целевую переменную, но и сами данные, которые подаются сети на вход. Для них будем использовать нормализацию через среднее и стандартное отклонение. Преобразуйте данные и повторите прошлый эксперимент. Скорее всего, имеет смысл увеличить число эпох обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prospective-disabled",
      "metadata": {
        "id": "prospective-disabled"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "opponent-decision",
      "metadata": {
        "id": "opponent-decision"
      },
      "source": [
        "Если вы все сделали правильно, то у вас должно было получиться качество, сравнимое с `Ridge` регрессией.\n",
        "\n",
        "**Мораль:** как видите, нам пришлось сделать очень много хитрых телодвижений, чтобы нейронная сеть работала хотя бы так же, как и простая линейная модель. Здесь, конечно, показан совсем экстремальный случай, когда без нормализации данных нейронная сеть просто не учится. Как правило, в реальности завести нейронную сеть из коробки не очень сложно, но вот заставить ее работать на полную &mdash; куда более трудоемкая задача. Написание пайплайнов обучения нейросетевых моделей требует большой аккуратности, а дебаг часто превращается в угадайку. К счастью, очень часто на помощь приходит интуиция, и мы надеемся, что вы сможете выработать ее в течение нашего курса. Начнем с двух советов, которые стоит принять на вооружение:\n",
        "\n",
        "- Обязательно начинаем любые эксперименты с бейзлайнов: без них мы бы не поняли, что нейронная сеть не учится в принципе.\n",
        "- При постановке эксперментов старайтесь делать минимальное количество изменений за раз (в идеале одно!): только так можно понять, какие конкретно изменения влияют на результат."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "royal-cholesterol",
      "metadata": {
        "id": "royal-cholesterol"
      },
      "source": [
        "## Часть 2. Улучшаем нейронную сеть (5 баллов)\n",
        "\n",
        "Продолжим экспериментировать с нейронной сетью, чтобы добиться еще лучшего качества."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ignored-active",
      "metadata": {
        "id": "ignored-active"
      },
      "source": [
        "**Задание 2.1 (1 балл).** Давайте попробуем другие оптимизаторы. Обучите нейросеть с помощью SGD+momentum и Adam. Опишите свои наблюдения и в дальнейших запусках используйте лучший оптимизатор. Для Adam обычно берут learning rate поменьше, в районе $10^{-3}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eastern-gnome",
      "metadata": {
        "id": "eastern-gnome"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hispanic-postage",
      "metadata": {
        "id": "hispanic-postage"
      },
      "source": [
        "**Задание 2.2 (1 балл).** Теперь сделаем нашу нейронную сеть более сложной. Попробуйте сделать сеть:\n",
        "\n",
        "- более широкой (то есть увеличить размерность скрытого слоя, например, вдвое)\n",
        "- более глубокой (то есть добавить еще один скрытый слой)\n",
        "\n",
        "Опишите, как увеличение числа параметров модели влияет на качество на обучающей и валидационной выборках."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d466362",
      "metadata": {
        "id": "1d466362"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454acdb1",
      "metadata": {
        "id": "454acdb1"
      },
      "source": [
        "**Задание 2.3 (1 балл).** Как вы должны были заметить, более сложная модель стала сильнее переобучаться. Попробуем добавить в обучение регуляризацию, чтобы бороться с переобучением. Добавьте слой дропаута ([`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)) с параметром $p=0.2$ после каждого линейного слоя, кроме последнего. Почитать про дропаут можете в следующем [блогпосте](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5) или в оригинальной [статье](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
        "\n",
        "Опишите результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483a941a",
      "metadata": {
        "id": "483a941a"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dcbadcc",
      "metadata": {
        "id": "9dcbadcc"
      },
      "source": [
        "**Задание 2.4 (1.5 балла).** Теперь, когда мы определились с выбором архитектуры нейронной сети, пора заняться рутиной DL-инженера &mdash; перебором гиперпараметров. Подберите оптимальное значение lr по значению MSE на валидации (по логарифмической сетке, достаточно посмотреть 3-4 значения), можете воспользоваться `verbose=False` в функции `train_and_validate`.\n",
        "\n",
        "Также подберем оптимальное значение параметра weight decay для данного lr. Weight decay &mdash; это аналог L2-регуляризации для нейронных сетей. Почитать о нем можно, например, [здесь](https://paperswithcode.com/method/weight-decay). В PyTorch он задается как параметр оптимизатора `weight_decay`. Подберите оптимальное значение weight decay по логарифимической сетке (его типичные значения лежат в диапазоне $[10^{-6}, 10^{-3}]$, но не забудьте включить нулевое значение в сетку).\n",
        "\n",
        "Постройте графики зависимости MSE на трейне и на валидации от значений параметров. Прокомментируйте получившиеся зависимости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8UqadoheOQSu",
      "metadata": {
        "id": "8UqadoheOQSu"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8nk3dvibo6SE",
      "metadata": {
        "id": "8nk3dvibo6SE"
      },
      "source": [
        "Как вы могли заметить, еще одна рутина DL-инженера &mdash; утомительное ожидание обучения моделей.\n",
        "\n",
        "**Задание 2.5 (0.5 балла).** Мы провели большое число экспериментов и подобрали оптимальную архитектуру и гиперпараметры. Пришло время обучить модель на полной обучающей выборке, померять качество на тестовой выборке и сравнить с бейзлайнами. Проделайте это."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pR4FJ4PYYajk",
      "metadata": {
        "id": "pR4FJ4PYYajk"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}